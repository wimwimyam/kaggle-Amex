{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, Subset\n",
    "import torch_optimizer as optim\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = './experiments/amex_transformer_finetune_v9/'\n",
    "if not os.path.exists(experiments_path):\n",
    "    os.makedirs(experiments_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = './experiments/amex_transformer_pretrain_v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./data/X2.npy\")\n",
    "y = np.load(\"./data/y.npy\")\n",
    "customer_list = np.load(\"./data/customer_list.npy\")\n",
    "is_train = np.load(\"./data/is_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"./data/train_data.csv\",index_col=0,nrows=1).columns[2:]\n",
    "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "dense_features = [col for col in features if col not in cat_features]\n",
    "features = cat_features + dense_features\n",
    "features_group = {}\n",
    "for i, col in enumerate(features):\n",
    "    g = col[0]\n",
    "    if g not in features_group:\n",
    "        features_group[g] = {}\n",
    "        if col in cat_features:\n",
    "            features_group[g]['cat'] = [i]\n",
    "        else:\n",
    "            features_group[g]['dense'] = [i]\n",
    "    else:\n",
    "        if col in cat_features:\n",
    "            if 'cat' in features_group[g]:\n",
    "                features_group[g]['cat'].append(i)\n",
    "            else:\n",
    "                features_group[g]['cat'] = [i]\n",
    "        else:\n",
    "            if 'dense' in features_group[g]:\n",
    "                features_group[g]['dense'].append(i)\n",
    "            else:\n",
    "                features_group[g]['dense'] = [i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B cat 2\n",
      "B dense 38\n",
      "D cat 9\n",
      "D dense 87\n",
      "P dense 3\n",
      "R dense 28\n",
      "S dense 21\n"
     ]
    }
   ],
   "source": [
    "for a in features_group:\n",
    "    for b in features_group[a]:\n",
    "        print(a,b,len(features_group[a][b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 8., 3., 3., 8., 3., 4., 6., 5., 3., 8.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmax(X[...,:11].reshape(-1,11),0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X[is_train]\n",
    "y_tr = y[is_train]\n",
    "train_customer = customer_list[is_train]\n",
    "\n",
    "X_test = X[~is_train]\n",
    "test_customer = customer_list[~is_train]\n",
    "\n",
    "del X,y,customer_list,is_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 5\n",
    "GROUPS = 5\n",
    "device = torch.device('cuda:1')\n",
    "kf = StratifiedKFold(GROUPS, shuffle=True, random_state=42)\n",
    "dataset = TensorDataset(torch.Tensor(X_tr), torch.Tensor(y_tr))\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'d_model': 768,\n",
    "         'emb_dim': 4,\n",
    "         'n_layers': 6,\n",
    "         'n_heads': 4,\n",
    "         'activation': 'relu',\n",
    "         'transformer_act': 'relu',\n",
    "         'use_cls': False,\n",
    "         'input_norm': False,\n",
    "         'input_layers': 0,\n",
    "         'tanh_scale': 0.3450840441113073,\n",
    "         'input_dropout': 0.10803114983077852,\n",
    "         'hidden_dropout': 0.23771720623629086,\n",
    "         'final_dropout': 0.1803505437404746,\n",
    "         'transformer_dropout': 0.24608225028381883,\n",
    "         'output_layers': 'mlp2',\n",
    "         'pe_std': 0.7232348735328199,\n",
    "         'optimizer': 'Lamb',\n",
    "         'lr': 0.001,\n",
    "         'weight_decay': 0.051712665649902206,\n",
    "         'optimizer_alpha': 0.07931217763278503,\n",
    "         'optimizer_beta': 0.0070573347096303885}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhEstimator(nn.Module):\n",
    "    def __init__(self, inp_size, tanh_scale=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(tanh_scale * torch.ones(inp_size))\n",
    "        self.beta = nn.Parameter(torch.zeros(inp_size))\n",
    "    def forward(self, inp):\n",
    "        x = torch.tanh(self.alpha * inp + self.beta)\n",
    "        return x\n",
    "\n",
    "class AmexModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        d_model = params['d_model']\n",
    "        emb_dim = params['emb_dim']\n",
    "        n_layers = params['n_layers']\n",
    "        n_heads = 2**params['n_heads']\n",
    "        \n",
    "        if params['activation'] == 'relu':\n",
    "            activation = nn.ReLU()\n",
    "        elif params['activation'] == 'gelu':\n",
    "            activation = nn.GELU()\n",
    "        elif params['activation'] == 'mish':\n",
    "            activation = nn.Mish()\n",
    "        \n",
    "        self.use_cls = params['use_cls']\n",
    "        \n",
    "        self.n_cat = [4, 8, 3, 3, 8, 3, 4, 6, 5, 3, 8]\n",
    "        self.n_dense = 177\n",
    "        self.features_group = features_group\n",
    "        self.inp_emb = nn.ModuleDict()\n",
    "        for key1 in self.features_group:\n",
    "            self.inp_emb[key1] = nn.ModuleDict()\n",
    "            for key2 in self.features_group[key1]:\n",
    "                if key2 == 'cat':\n",
    "                    self.inp_emb[key1][key2] = nn.ModuleList()\n",
    "                    for i in self.features_group[key1][key2]:\n",
    "                        self.inp_emb[key1][key2].append(nn.Embedding(self.n_cat[i],emb_dim))\n",
    "                else:\n",
    "                    d = len(self.features_group[key1][key2])\n",
    "                    if 'cat' in self.features_group[key1]:\n",
    "                        d += len(self.features_group[key1]['cat']) * emb_dim\n",
    "                    self.inp_emb[key1][key2] = nn.Sequential(nn.Linear(d, d_model),\n",
    "                                                             nn.Dropout(0.1),\n",
    "                                                             nn.Mish(),\n",
    "                                                             nn.Linear(d_model,d_model))\n",
    "        \n",
    "        if params['input_norm']:\n",
    "            self.norm = nn.BatchNorm1d(self.n_dense)\n",
    "        else:\n",
    "            self.norm = nn.Identity()\n",
    "            \n",
    "        self.dense_norm = TanhEstimator(self.n_dense, params['tanh_scale'])\n",
    "        self.post_norm = nn.BatchNorm1d(len(self.features_group) * d_model)\n",
    "        self.proj = [nn.Dropout(params['input_dropout']),nn.Linear(len(self.features_group) * d_model, d_model)]\n",
    "        for _ in range(params['input_layers']):\n",
    "            self.proj.extend([nn.Dropout(params['hidden_dropout']), activation, nn.Linear(d_model, d_model)])\n",
    "        self.proj = nn.Sequential(*self.proj)\n",
    "        \n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model,n_heads,4*d_model,\n",
    "                                                                            params['transformer_dropout'],\n",
    "                                                                            activation=params['transformer_act'],\n",
    "                                                                            norm_first=True,batch_first=True)\n",
    "                                                 ,n_layers)\n",
    "        \n",
    "        if params['output_layers'] == 'linear':\n",
    "            self.fc = nn.Sequential(nn.Dropout(params['final_dropout']), nn.Linear(d_model, 1))\n",
    "        elif params['output_layers'] == 'mlp':\n",
    "            self.fc = nn.Sequential(nn.Dropout(params['hidden_dropout']), nn.Linear(d_model, d_model), activation,\n",
    "                                    nn.Dropout(params['final_dropout']), nn.Linear(d_model, 1))\n",
    "        elif params['output_layers'] == 'mlp2':\n",
    "            self.fc = nn.Sequential(nn.Dropout(params['hidden_dropout']), nn.Linear(d_model, 4*d_model), activation,\n",
    "                                    nn.Dropout(params['final_dropout']), nn.Linear(4*d_model, 1))\n",
    "        \n",
    "        self.ae_fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(d_model, 1095))\n",
    "        self.new_fc = nn.Sequential(nn.Dropout(params['final_dropout']), nn.Linear(d_model, 1))\n",
    "        \n",
    "        self.pe = nn.Parameter(torch.empty([13,d_model]))\n",
    "        nn.init.normal_(self.pe, std=params['pe_std'])\n",
    "        \n",
    "        self.cls = nn.Parameter(torch.empty(d_model))\n",
    "        nn.init.normal_(self.cls)\n",
    "        \n",
    "            \n",
    "    def forward(self, inp):\n",
    "        missing_nodes_mask = torch.all(torch.isnan(inp),dim=-1)\n",
    "        inp[torch.isnan(inp)] = 0\n",
    "        \n",
    "        inp_cat = inp[...,:len(self.n_cat)]\n",
    "        inp_dense = inp[...,len(self.n_cat):]\n",
    "#         inp_dense = self.dense_norm(inp_dense)\n",
    "#         inp_dense = self.norm(inp_dense.transpose(1,2)).transpose(1,2)\n",
    "        inp = torch.cat([inp_cat,inp_dense],dim=-1)\n",
    "        X = []\n",
    "        for key1 in self.features_group:\n",
    "            if 'cat' in self.features_group[key1]:\n",
    "                X_list = [inp[...,self.features_group[key1]['dense']]]\n",
    "                for i, idx in enumerate(self.features_group[key1]['cat']):\n",
    "                    X_list.append(self.inp_emb[key1]['cat'][i](inp[...,idx].long()))\n",
    "                X_list = torch.cat(X_list,dim=-1)\n",
    "                X.append(self.inp_emb[key1]['dense'](X_list))\n",
    "            else:\n",
    "                X.append(self.inp_emb[key1]['dense'](inp[...,self.features_group[key1]['dense']]))\n",
    "        X = torch.cat(X,dim=-1)\n",
    "        X = X.permute(0,2,1)\n",
    "        X = self.post_norm(X)\n",
    "        X = X.permute(0,2,1)\n",
    "        X = self.proj(X)\n",
    "        X = X + self.pe\n",
    "        \n",
    "        if self.use_cls:\n",
    "            X = torch.cat([X,self.cls.reshape(1,1,-1).repeat(len(X),1,1)],dim=1)\n",
    "            mask = torch.cat([missing_nodes_mask,torch.zeros([len(X),1],device=X.device).bool()],dim=1)\n",
    "            X = self.transformer(X, src_key_padding_mask=mask)\n",
    "        else:\n",
    "            X = self.transformer(X, src_key_padding_mask=missing_nodes_mask)\n",
    "        \n",
    "        X = X[:,-1]\n",
    "        \n",
    "        y = self.new_fc(X).squeeze(-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def amex_metric(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "    score = 0.5 * (gini[1]/gini[0] + top_four)\n",
    "    return score, gini[1]/gini[0], top_four\n",
    "\n",
    "def train_one_epoch(model, optimizer, scheduler, train_dataloader, device = torch.device('cpu')):\n",
    "    model.train()\n",
    "    MA_loss = 0\n",
    "    count = 0\n",
    "    for X,y in train_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(X)\n",
    "                \n",
    "        loss = criterion(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        MA_loss += loss.item() * len(y)\n",
    "        count += len(y)\n",
    "    MA_loss /= count\n",
    "    return MA_loss\n",
    "\n",
    "def evaluation(model, val_dataloader, device = torch.device('cpu')):\n",
    "    model.eval()\n",
    "    MA_loss = 0\n",
    "    count = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for X,y in val_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred,y)\n",
    "            MA_loss += loss.item() * len(y)\n",
    "            count += len(y)\n",
    "            predictions.append(pred.cpu())\n",
    "            labels.append(y.cpu())\n",
    "        MA_loss /= count\n",
    "    predictions = torch.cat(predictions,dim=0).numpy()\n",
    "    labels = torch.cat(labels,dim=0).numpy()\n",
    "    score, gini, top4 = amex_metric(labels, predictions)\n",
    "    return MA_loss, score, gini, top4, predictions, labels\n",
    "\n",
    "def predict(model, test_dataloader, device = torch.device('cpu')):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X in test_dataloader:\n",
    "            X = X[0].to(device)\n",
    "            predictions.append(model(X).cpu())\n",
    "    predictions = torch.cat(predictions,dim=0).numpy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c6affb8df147bd9c5529100b9b6fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train_loss 0.2514926267985525\n",
      "val_loss 0.217480701352056\n",
      "val_score 0.7944007272603442\n",
      "val_gini 0.923312913394437\n",
      "val_top4 0.6654885411262512\n",
      "best_score 0.7944007272603442\n",
      "epoch 1\n",
      "train_loss 0.218040412447972\n",
      "val_loss 0.213697245594278\n",
      "val_score 0.7993720207472248\n",
      "val_gini 0.9259341426411476\n",
      "val_top4 0.672809898853302\n",
      "best_score 0.7993720207472248\n",
      "epoch 2\n",
      "train_loss 0.21267165930411003\n",
      "val_loss 0.2134722718809497\n",
      "val_score 0.8014101349511946\n",
      "val_gini 0.926055126031082\n",
      "val_top4 0.6767651438713074\n",
      "best_score 0.8014101349511946\n",
      "epoch 3\n",
      "train_loss 0.20800826090840654\n",
      "val_loss 0.21262237957863805\n",
      "val_score 0.8026332240431242\n",
      "val_gini 0.926692005222784\n",
      "val_top4 0.6785744428634644\n",
      "best_score 0.8026332240431242\n",
      "epoch 4\n",
      "train_loss 0.2049480298710935\n",
      "val_loss 0.212965349057335\n",
      "val_score 0.8024430725301754\n",
      "val_gini 0.9267324513843559\n",
      "val_top4 0.6781536936759949\n",
      "best_score 0.8026332240431242\n",
      "fold: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99e6fb7f8354b4189834d31968d8d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train_loss 0.25008610190625963\n",
      "val_loss 0.22147220764730674\n",
      "val_score 0.7847598245457437\n",
      "val_gini 0.9203990798623614\n",
      "val_top4 0.649120569229126\n",
      "best_score 0.7847598245457437\n",
      "epoch 1\n",
      "train_loss 0.21746256406413778\n",
      "val_loss 0.21893976183773306\n",
      "val_score 0.7880609104493607\n",
      "val_gini 0.92275144049711\n",
      "val_top4 0.6533703804016113\n",
      "best_score 0.7880609104493607\n",
      "epoch 2\n",
      "train_loss 0.2119448023884656\n",
      "val_loss 0.21778856052846518\n",
      "val_score 0.7914496391368477\n",
      "val_gini 0.9233856855536637\n",
      "val_top4 0.6595135927200317\n",
      "best_score 0.7914496391368477\n",
      "epoch 3\n",
      "train_loss 0.20716276186305052\n",
      "val_loss 0.21792994728815898\n",
      "val_score 0.7918758596488561\n",
      "val_gini 0.9235648921149424\n",
      "val_top4 0.6601868271827698\n",
      "best_score 0.7918758596488561\n",
      "epoch 4\n",
      "train_loss 0.20449584493590467\n",
      "val_loss 0.21784341874143193\n",
      "val_score 0.7916095244019545\n",
      "val_gini 0.9235792134462429\n",
      "val_top4 0.659639835357666\n",
      "best_score 0.7918758596488561\n",
      "fold: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7a6ba69d6249aebe60a99d01e66381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train_loss 0.24995888174412637\n",
      "val_loss 0.2211523208113587\n",
      "val_score 0.7898502468928821\n",
      "val_gini 0.9211967229575172\n",
      "val_top4 0.6585037708282471\n",
      "best_score 0.7898502468928821\n",
      "epoch 1\n",
      "train_loss 0.21794605671360506\n",
      "val_loss 0.21883061438100465\n",
      "val_score 0.7908507138191777\n",
      "val_gini 0.922314077555958\n",
      "val_top4 0.6593873500823975\n",
      "best_score 0.7908507138191777\n",
      "epoch 2\n",
      "train_loss 0.21197987826509848\n",
      "val_loss 0.2171115383528388\n",
      "val_score 0.7917567374657918\n",
      "val_gini 0.9235791330240823\n",
      "val_top4 0.6599343419075012\n",
      "best_score 0.7917567374657918\n",
      "epoch 3\n",
      "train_loss 0.20725361474232967\n",
      "val_loss 0.21712437809278645\n",
      "val_score 0.7925831270958735\n",
      "val_gini 0.9237592007211355\n",
      "val_top4 0.6614070534706116\n",
      "best_score 0.7925831270958735\n",
      "epoch 4\n",
      "train_loss 0.2047139591011921\n",
      "val_loss 0.21766199212261023\n",
      "val_score 0.7928146835041087\n",
      "val_gini 0.9238436452293477\n",
      "val_top4 0.6617857217788696\n",
      "best_score 0.7928146835041087\n",
      "fold: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5631ad361d4040a0bdc5e004a8d3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train_loss 0.24436584343956835\n",
      "val_loss 0.2227645065399299\n",
      "val_score 0.7827368633287728\n",
      "val_gini 0.9200287374531387\n",
      "val_top4 0.6454449892044067\n",
      "best_score 0.7827368633287728\n",
      "epoch 1\n",
      "train_loss 0.21764123964243096\n",
      "val_loss 0.2198459197257308\n",
      "val_score 0.7898255941795339\n",
      "val_gini 0.9223820681426982\n",
      "val_top4 0.6572691202163696\n",
      "best_score 0.7898255941795339\n",
      "epoch 2\n",
      "train_loss 0.2114167541431981\n",
      "val_loss 0.21761635335843396\n",
      "val_score 0.7913909940006061\n",
      "val_gini 0.9232406195167152\n",
      "val_top4 0.6595413684844971\n",
      "best_score 0.7913909940006061\n",
      "epoch 3\n",
      "train_loss 0.20667496702358043\n",
      "val_loss 0.2179135637519089\n",
      "val_score 0.7928991494504984\n",
      "val_gini 0.9233956094440573\n",
      "val_top4 0.6624026894569397\n",
      "best_score 0.7928991494504984\n",
      "epoch 4\n",
      "train_loss 0.2038167330472829\n",
      "val_loss 0.21808636129150513\n",
      "val_score 0.7919174859436326\n",
      "val_gini 0.9233678836647615\n",
      "val_top4 0.6604670882225037\n",
      "best_score 0.7928991494504984\n",
      "fold: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e123727f8c3d47f69ea66926de80f9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train_loss 0.2522133374846847\n",
      "val_loss 0.21878064356796081\n",
      "val_score 0.7912643230685048\n",
      "val_gini 0.9225665284650432\n",
      "val_top4 0.6599621176719666\n",
      "best_score 0.7912643230685048\n",
      "epoch 1\n",
      "train_loss 0.2175909398571073\n",
      "val_loss 0.21632504233075453\n",
      "val_score 0.7948967738124564\n",
      "val_gini 0.9241928901618391\n",
      "val_top4 0.6656006574630737\n",
      "best_score 0.7948967738124564\n",
      "epoch 2\n",
      "train_loss 0.2120465229176942\n",
      "val_loss 0.2150374452747124\n",
      "val_score 0.7945410077889815\n",
      "val_gini 0.9251644740740568\n",
      "val_top4 0.6639175415039062\n",
      "best_score 0.7948967738124564\n",
      "epoch 3\n",
      "train_loss 0.2070863041714583\n",
      "val_loss 0.21571723355979597\n",
      "val_score 0.7954540126103411\n",
      "val_gini 0.9252652868783969\n",
      "val_top4 0.6656427383422852\n",
      "best_score 0.7954540126103411\n",
      "epoch 4\n",
      "train_loss 0.20410489773783605\n",
      "val_loss 0.21568108656676246\n",
      "val_score 0.7945852276254273\n",
      "val_gini 0.925042509350891\n",
      "val_top4 0.6641279458999634\n",
      "best_score 0.7954540126103411\n",
      "0.7947352850070364 0.9244926186894691 0.6649779513246036\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(len(y_tr))\n",
    "test_pred = np.zeros(len(X_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=0,shuffle=False,drop_last=False)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_tr, y_tr)):\n",
    "    print(\"fold:\",fold)\n",
    "    model_path = experiments_path + f\"model_fold{fold}.pt\"\n",
    "    \n",
    "    train_dataset = Subset(dataset, train_index)\n",
    "    val_dataset = Subset(dataset, val_index)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=0,shuffle=True,drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=0,shuffle=False,drop_last=False)\n",
    "    \n",
    "    model = AmexModel(param).to(device)\n",
    "    pretrain_model_path = pretrain_path + \"model.pt\"\n",
    "    model.load_state_dict(torch.load(pretrain_model_path,map_location=device), strict=False)\n",
    "    if param['optimizer'] == 'Lamb':\n",
    "        optimizer = optim.Lamb(model.parameters(),\n",
    "                               lr=param['lr'],\n",
    "                               weight_decay=param['weight_decay'],\n",
    "                               betas = (1 - param['optimizer_alpha'], 1 - param['optimizer_beta']))\n",
    "    elif param['optimizer'] == 'AdamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                       lr=param['lr'],\n",
    "                                       weight_decay=param['weight_decay'],\n",
    "                                       betas = (1 - param['optimizer_alpha'], 1 - param['optimizer_beta']))\n",
    "    elif param['optimizer'] == 'Ranger':\n",
    "        optimizer = optim.Ranger(model.parameters(),\n",
    "                                   lr=param['lr'],\n",
    "                                   weight_decay=param['weight_decay'],\n",
    "                                   betas = (1 - param['optimizer_alpha'], 1 - param['optimizer_beta']))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, EPOCHS*len(train_loader))\n",
    "    \n",
    "    best_score = -1.0\n",
    "    \n",
    "    for epoch in trange(EPOCHS):\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device)\n",
    "        val_loss, val_score, val_gini, val_top4, val_pred, val_label = evaluation(model, val_loader, device)\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            oof[val_index] = val_pred\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(f\"epoch {epoch}\")\n",
    "        print(f\"train_loss {train_loss}\")\n",
    "        print(f\"val_loss {val_loss}\")\n",
    "        print(f\"val_score {val_score}\")\n",
    "        print(f\"val_gini {val_gini}\")\n",
    "        print(f\"val_top4 {val_top4}\")\n",
    "        print(f\"best_score {best_score}\")\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "    test_pred += predict(model, test_loader, device) / GROUPS\n",
    "        \n",
    "cv_score, cv_gini, cv_top4 = amex_metric(y_tr, oof)\n",
    "print(cv_score, cv_gini, cv_top4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(oof, index=train_customer).to_csv(experiments_path + \"oof.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"./data/sample_submission.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[test_customer,'prediction'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</th>\n",
       "      <td>-4.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397d4263dafa1daedef5</th>\n",
       "      <td>-8.055628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5e400fc98e7bd43ce8</th>\n",
       "      <td>-3.018232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf6e56734528702d694</th>\n",
       "      <td>-1.410013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a4693dd914fca22557</th>\n",
       "      <td>1.981464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5d60460dba6dedc41e</th>\n",
       "      <td>-5.183532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a4f0ca3de613b0b2ad</th>\n",
       "      <td>1.422638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475cb095d2443a68030f1</th>\n",
       "      <td>-0.188733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffddef1fc3643ea179c93245b68dca0f36941cd83977822e8b356988ca4d07</th>\n",
       "      <td>-0.616730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61cceb803ea8ec37634d</th>\n",
       "      <td>-3.290130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924621 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    prediction\n",
       "customer_ID                                                   \n",
       "00000469ba478561f23a92a868bd366de6f6527a684c9a2...   -4.000736\n",
       "00001bf2e77ff879fab36aa4fac689b9ba411dae63ae397...   -8.055628\n",
       "0000210045da4f81e5f122c6bde5c2a617d03eef67f82c5...   -3.018232\n",
       "00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976cf...   -1.410013\n",
       "00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9a...    1.981464\n",
       "...                                                        ...\n",
       "ffff952c631f2c911b8a2a8ca56ea6e656309a83d2f64c5...   -5.183532\n",
       "ffffcf5df59e5e0bba2a5ac4578a34e2b5aa64a1546cd3a...    1.422638\n",
       "ffffd61f098cc056dbd7d2a21380c4804bbfe60856f475c...   -0.188733\n",
       "ffffddef1fc3643ea179c93245b68dca0f36941cd839778...   -0.616730\n",
       "fffffa7cf7e453e1acc6a1426475d5cb9400859f82ff61c...   -3.290130\n",
       "\n",
       "[924621 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(experiments_path + f\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch15]",
   "language": "python",
   "name": "conda-env-.conda-pytorch15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
